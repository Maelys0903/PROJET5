import requests
import pandas as pd
import time
from tqdm import tqdm

BASE_URL = "https://api.stackexchange.com/2.3/questions"
SITE = "stackoverflow"
PAGESIZE = 50

API_KEY = None

ef fetch_questions(page=1, pagesize=50, tagged=None):
    params = {
        "site": SITE,
        "pagesize": pagesize,
        "page": page,
        "order": "desc",
        "sort": "votes",
        "filter": "withbody",  # Pour inclure le corps des questions
    }
    if tagged:
        params["tagged"] = tagged
    if API_KEY:
        params["key"] = API_KEY

    response = requests.get(BASE_URL, params=params)
    response.raise_for_status()
    return response.json()

def collect_questions(n_pages=10, tagged=None):
    all_items = []

    for page in tqdm(range(1, n_pages + 1)):
        data = fetch_questions(page=page, tagged=tagged)
        items = data.get("items", [])
        all_items.extend(items)
        time.sleep(1)  # Pour respecter les limites de l’API

    return all_items

def questions_to_df(questions):
    data = []

    for q in questions:
        data.append({
            "question_id": q.get("question_id"),
            "title": q.get("title"),
            "body": q.get("body"),
            "tags": q.get("tags"),
            "creation_date": q.get("creation_date"),
            "score": q.get("score"),
            "view_count": q.get("view_count"),
            "answer_count": q.get("answer_count"),
            "is_answered": q.get("is_answered")
        })

    return pd.DataFrame(data)

# Exemple : récupérer 250 questions populaires (5 pages de 50 questions)
questions = collect_questions(n_pages=5)
df_questions = questions_to_df(questions)

# Aperçu du DataFrame
df_questions.head()

df_questions.to_csv("stack_questions_api.csv", index=False)